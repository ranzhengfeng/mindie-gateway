worker_processes auto;

events {
    worker_connections 4096; # 根据需要调整
}

http {
    resolver 127.0.0.11 valid=30s ipv6=off; # 使用 Docker 内置 DNS 解析器，避免mindie-redis无法解析的问题.
    lua_package_path "/usr/local/openresty/nginx/lua/?.lua;;";
    client_max_body_size 2048m;   # 根据模型响应大小调整
    proxy_read_timeout 3600s;   # 长时间运行的请求
    proxy_send_timeout 3600s;

    upstream mindie_backend {
        server 192.168.242.220:1025;   # 替换为你的 MindIE 实例地址
    }

    server {
        listen 80;
        server_name _;

        # 健康检查或根页面
        location = / {
            return 200 "MindIE API Gateway\n";
        }

        # OpenAI-兼容 API 一般以 /v1/ 为前缀，全部流量通过 Lua 校验
        location /v1/ {
            # access phase 调用 Lua 检查 API Key
            access_by_lua_file /usr/local/openresty/nginx/lua/auth.lua;

            # 转发到后端 MindIE
            proxy_pass http://mindie_backend;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            proxy_buffering off;    # 对大模型流式响应非常重要
            proxy_request_buffering off;
        }

        # 可添加一个用于管理员的 key 管理端点（如果你想通过 API 管理 keys 可实现）
    }
}

